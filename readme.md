To start LLM Runner - ollama now and restart at login:
```
brew services start ollama
```
 How to start LLM model Mistral using Runner Ollama?
```
  ollama run mistral
```

How to run the Isolation Forest ML algorithm to deduct anomaly?

Streamlit is a **Python framework** that makes it super easy to build **interactive web apps for data science, machine learning, and analytics** — all with just a few lines of Python.

Or, if you don't want/need a background service you can just run:

```
 /opt/homebrew/opt/ollama/bin/ollama serve
 streamlit run /Users/elangovanmadhivanan/Documents/GitHub/FraudDetect/IsolationForest_Mistral.py "<filename>"
```

How to start/stop the LLM model from running ?
```
/opt/homebrew/opt/ollama/bin/ollama start mistral
/opt/homebrew/opt/ollama/bin/ollama stop mistral
```


